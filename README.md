# Build a LLM from scratch (Rust 语言版)

## 快速开始

## 进度
- [x] 01. 理解大型语言模型（Understanding Large Language Models）
- [x] 02. 处理文本数据（Working with Text Data）​
- [x] 03. 编码注意力机制（Coding Attention Mechanisms）​
- [x] 04. 从零实现GPT模型（Implementing a GPT Model from Scratch）​
- [x] 05. 在无标注数据上进行预训练（Pretraining on Unlabeled Data）​​
- [x] 06. 进行文本分类的微调（Fine-tuning for Classification）​
- [ ] 07. 进行遵循指令的微调（Fine-tuning to Follow Instructions）​

## 温馨提示
- PyTorch 使用 macOS 的 MPS 会导致计算出错，使得训练误差不会按预期收敛
- burn 的 Module::to_device 转移后的模型不再支持反向传播

## 参考文献
- https://github.com/rasbt/LLMs-from-scratch
